{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3da3d0e3-e839-491c-abf1-4f2f1ca9b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data already loaded. Proceed to Cell 2.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nfl_data_py as nfl\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Check if data exists to avoid re-downloading\n",
    "if 'pbp' not in locals():\n",
    "    years = [2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
    "    print(f\"üì• Downloading NFL Data for {years}...\")\n",
    "    try:\n",
    "        schedule = nfl.import_schedules(years)\n",
    "        pbp = nfl.import_pbp_data(years)\n",
    "        print(\"‚úÖ Data Loaded Successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {e}\")\n",
    "else:\n",
    "    print(\"‚úÖ Data already loaded. Proceed to Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7b00cdd-3435-478b-ab4e-6c7eb566e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Processing Stats (Restoring & Refining the Golden Era Model)...\n",
      "üèà Building QB Database...\n",
      "üöÄ Starting Walk-Forward Validation on 15 Refined Features...\n",
      "\n",
      "============================================================\n",
      "üïµÔ∏è  WALK-FORWARD TEST RESULTS (2023-2024)\n",
      "============================================================\n",
      "1. PERFORMANCE METRICS\n",
      "   RMSE: 13.5290\n",
      "   MAE:  10.4324\n",
      "\n",
      "2. BETTING SIMULATION (Refined Golden Model)\n",
      "   Edge > 1.5: 187-192-12 (49.34%)\n",
      "   Edge > 2.5: 146-144-8 (50.34%)\n",
      "   Edge > 3.5: 113-95-5 (54.33%)\n",
      "\n",
      "3. FEATURE IMPORTANCE\n",
      "pythag_diff               | 0.1350 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "edsr_diff                 | 0.1300 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "qb_diff                   | 0.1036 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "ypp_diff                  | 0.0976 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "home_field_strength       | 0.0913 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "home_qb_volatility        | 0.0592 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "away_qb_volatility        | 0.0545 | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "st_diff                   | 0.0527 | ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "sack_mismatch_home        | 0.0516 | ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "rz_diff                   | 0.0445 | ‚ñà‚ñà‚ñà‚ñà\n",
      "sack_mismatch_away        | 0.0441 | ‚ñà‚ñà‚ñà‚ñà\n",
      "turnover_diff             | 0.0408 | ‚ñà‚ñà‚ñà‚ñà\n",
      "rest_diff                 | 0.0387 | ‚ñà‚ñà‚ñà‚ñà\n",
      "penalty_diff              | 0.0302 | ‚ñà‚ñà‚ñà\n",
      "roof                      | 0.0262 | ‚ñà‚ñà\n",
      "\n",
      "üöÄ Retraining Master Model on ALL Data (2018-2024)...\n",
      "‚úÖ Master Model Ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- 1. FEATURE ENGINEERING ---\n",
    "print(\"‚öôÔ∏è Processing Stats (Restoring & Refining the Golden Era Model)...\")\n",
    "\n",
    "# Garbage Time Filter\n",
    "pbp_clean = pbp[((pbp['pass'] == 1) | (pbp['rush'] == 1)) & (pbp['wp'] > 0.05) & (pbp['wp'] < 0.95)].dropna(subset=['epa', 'posteam', 'defteam', 'success', 'yards_gained'])\n",
    "\n",
    "def get_team_stats(df, full_pbp):\n",
    "    # 1. Base Stats\n",
    "    gen = df.groupby(['season', 'week', 'posteam']).agg({'epa': 'mean', 'yards_gained': 'mean'}).reset_index().rename(columns={'posteam': 'team', 'epa': 'off_epa', 'yards_gained': 'off_ypp'})\n",
    "    \n",
    "    # 2. Early Down Success Rate (EDSR)\n",
    "    edsr = df[df['down'].isin([1, 2])].groupby(['season', 'week', 'posteam'])['success'].mean().reset_index().rename(columns={'posteam': 'team', 'success': 'off_edsr'})\n",
    "\n",
    "    # 3. Trench Warfare (Sack Rates)\n",
    "    pass_plays = full_pbp[full_pbp['pass'] == 1]\n",
    "    off_sacks = pass_plays.groupby(['season', 'week', 'posteam'])['sack'].mean().reset_index().rename(columns={'posteam': 'team', 'sack': 'off_sack_rate'})\n",
    "    def_sacks = pass_plays.groupby(['season', 'week', 'defteam'])['sack'].mean().reset_index().rename(columns={'defteam': 'team', 'sack': 'def_sack_rate'})\n",
    "\n",
    "    # 4. Special Teams, Turnovers & Penalties\n",
    "    st = full_pbp[full_pbp['special_teams_play'] == 1].groupby(['season', 'week', 'posteam'])['epa'].mean().reset_index().rename(columns={'posteam': 'team', 'epa': 'st_epa'})\n",
    "    \n",
    "    tos = full_pbp.groupby(['season', 'week', 'posteam']).agg({'fumble_lost': 'sum', 'interception': 'sum'}).reset_index()\n",
    "    tos['turnovers_lost'] = tos['fumble_lost'] + tos['interception']\n",
    "    \n",
    "    penalties = full_pbp[full_pbp['penalty'] == 1].groupby(['season', 'week', 'penalty_team']).agg({'penalty_yards': 'sum'}).reset_index().rename(columns={'penalty_team': 'team', 'penalty_yards': 'pen_yards'})\n",
    "    \n",
    "    # 5. Red Zone Efficiency\n",
    "    rz = df[df['yardline_100'] <= 20].groupby(['season', 'week', 'posteam'])['epa'].mean().reset_index().rename(columns={'posteam': 'team', 'epa': 'off_rz_epa'})\n",
    "\n",
    "    # Merge All\n",
    "    merged = gen.merge(edsr, on=['season', 'week', 'team'], how='left')\n",
    "    merged = merged.merge(off_sacks, on=['season', 'week', 'team'], how='left').merge(def_sacks, on=['season', 'week', 'team'], how='left')\n",
    "    merged = merged.merge(st, on=['season', 'week', 'team'], how='left')\n",
    "    merged = merged.merge(tos[['season', 'week', 'posteam', 'turnovers_lost']].rename(columns={'posteam': 'team'}), on=['season', 'week', 'team'], how='left')\n",
    "    merged = merged.merge(penalties, on=['season', 'week', 'team'], how='left')\n",
    "    merged = merged.merge(rz, on=['season', 'week', 'team'], how='left')\n",
    "    \n",
    "    # Pass Splits\n",
    "    pass_df = df[df['pass'] == 1].groupby(['season', 'week', 'posteam'])['epa'].mean().reset_index().rename(columns={'posteam': 'team', 'epa': 'off_pass_epa'})\n",
    "    merged = merged.merge(pass_df, on=['season', 'week', 'team'], how='left')\n",
    "    \n",
    "    return merged.fillna(0)\n",
    "\n",
    "stats = get_team_stats(pbp_clean, pbp).sort_values(['team', 'season', 'week'])\n",
    "\n",
    "# Rolling Averages\n",
    "metrics = ['off_epa', 'off_ypp', 'off_pass_epa', \n",
    "           'off_edsr', 'off_sack_rate', 'def_sack_rate', \n",
    "           'st_epa', 'turnovers_lost', 'pen_yards', 'off_rz_epa']\n",
    "\n",
    "for col in metrics:\n",
    "    stats[f'{col}_long'] = stats.groupby(['team', 'season'])[col].transform(lambda x: x.shift(1).ewm(span=10).mean())\n",
    "    stats[f'{col}_short'] = stats.groupby(['team', 'season'])[col].transform(lambda x: x.shift(1).ewm(span=3).mean())\n",
    "\n",
    "# Pythagorean Wins & Luck\n",
    "def add_standings(games_df):\n",
    "    home = games_df[['season', 'week', 'home_team', 'home_score', 'away_score']].rename(columns={'home_team': 'team', 'home_score': 'pf', 'away_score': 'pa'})\n",
    "    away = games_df[['season', 'week', 'away_team', 'away_score', 'home_score']].rename(columns={'away_team': 'team', 'away_score': 'pf', 'home_score': 'pa'})\n",
    "    results = pd.concat([home, away]).sort_values(['team', 'season', 'week']).dropna()\n",
    "    \n",
    "    results['win'] = (results['pf'] > results['pa']).astype(int)\n",
    "    results['cum_pf'] = results.groupby(['team', 'season'])['pf'].transform(lambda x: x.shift(1).cumsum())\n",
    "    results['cum_pa'] = results.groupby(['team', 'season'])['pa'].transform(lambda x: x.shift(1).cumsum())\n",
    "    results['cum_wins'] = results.groupby(['team', 'season'])['win'].transform(lambda x: x.shift(1).cumsum())\n",
    "    results['games_played'] = results.groupby(['team', 'season'])['win'].transform(lambda x: x.shift(1).expanding().count()).fillna(0)\n",
    "    \n",
    "    results['pythag_wins'] = np.where(results['cum_pf'] == 0, 0, (results['cum_pf']**2.37) / ((results['cum_pf']**2.37) + (results['cum_pa']**2.37)))\n",
    "    results['win_pct'] = np.where(results['games_played'] > 0, results['cum_wins'] / results['games_played'], 0)\n",
    "    results['luck_metric'] = results['win_pct'] - results['pythag_wins']\n",
    "    \n",
    "    return results[['season', 'week', 'team', 'pythag_wins', 'luck_metric']].fillna(0)\n",
    "\n",
    "standings = add_standings(schedule)\n",
    "stats = stats.merge(standings, on=['season', 'week', 'team'], how='left').fillna(0)\n",
    "stats = stats.dropna()\n",
    "\n",
    "# QB Database\n",
    "print(\"üèà Building QB Database...\")\n",
    "qb_data = pbp_clean[pbp_clean['pass'] == 1].groupby(['season', 'posteam', 'name']).agg({'epa': 'mean', 'play_id': 'count'}).reset_index()\n",
    "qb_data = qb_data[qb_data['play_id'] > 15]\n",
    "qb_stability = qb_data.groupby(['season', 'posteam'])['epa'].std().reset_index().rename(columns={'epa': 'qb_volatility', 'posteam': 'team'}).fillna(0)\n",
    "stats = stats.merge(qb_stability, on=['season', 'team'], how='left')\n",
    "\n",
    "# Prepare Games\n",
    "games = schedule[schedule['game_type'] == 'REG'].copy()\n",
    "games = games.drop(columns=['home_rest', 'away_rest'], errors='ignore')\n",
    "games['roof'] = games['roof'].map({'outdoors': 0, 'open': 0, 'closed': 1, 'dome': 1}).fillna(0)\n",
    "\n",
    "# Expanding Window for Home Field Strength\n",
    "games_sorted = games.sort_values(['season', 'week'])\n",
    "home_results = games_sorted[['home_team', 'result']].rename(columns={'home_team': 'team'})\n",
    "games['home_field_strength'] = home_results.groupby('team')['result'].transform(lambda x: x.shift(1).expanding().mean()).fillna(2.0)\n",
    "\n",
    "# Rest Days\n",
    "games['gameday'] = pd.to_datetime(games['gameday'])\n",
    "rest_df = pd.concat([games[['season', 'week', 'gameday', 'home_team']].rename(columns={'home_team': 'team'}), \n",
    "                     games[['season', 'week', 'gameday', 'away_team']].rename(columns={'away_team': 'team'})]).sort_values(['team', 'gameday'])\n",
    "rest_df['rest'] = (rest_df['gameday'] - rest_df.groupby('team')['gameday'].shift(1)).dt.days.fillna(7).clip(upper=14)\n",
    "games = games.merge(rest_df[['season', 'week', 'team', 'rest']], left_on=['season', 'week', 'home_team'], right_on=['season', 'week', 'team']).rename(columns={'rest': 'home_rest'}).drop(columns=['team'])\n",
    "games = games.merge(rest_df[['season', 'week', 'team', 'rest']], left_on=['season', 'week', 'away_team'], right_on=['season', 'week', 'team']).rename(columns={'rest': 'away_rest'}).drop(columns=['team'])\n",
    "\n",
    "# Merge Stats\n",
    "cols_base = [f'{m}{s}' for m in metrics for s in ['_long', '_short']] + ['qb_volatility', 'pythag_wins', 'luck_metric']\n",
    "for side in ['home', 'away']:\n",
    "    games = games.merge(stats[['season', 'week', 'team'] + cols_base], left_on=['season', 'week', f'{side}_team'], right_on=['season', 'week', 'team'])\n",
    "    games.rename(columns={c: f'{side}_{c}' for c in cols_base}, inplace=True)\n",
    "    games.drop(columns=['team'], inplace=True)\n",
    "\n",
    "# --- FEATURE ENGINEERING (Golden Era - Trimmed) ---\n",
    "games['qb_diff'] = games['home_off_pass_epa_long'] - games['away_off_pass_epa_long']\n",
    "games['edsr_diff'] = games['home_off_edsr_long'] - games['away_off_edsr_long']\n",
    "games['ypp_diff'] = games['home_off_ypp_long'] - games['away_off_ypp_long']\n",
    "games['pythag_diff'] = games['home_pythag_wins'] - games['away_pythag_wins']\n",
    "games['rest_diff'] = games['home_rest'] - games['away_rest']\n",
    "games['st_diff'] = games['home_st_epa_long'] - games['away_st_epa_long']\n",
    "games['turnover_diff'] = games['home_turnovers_lost_long'] - games['away_turnovers_lost_long']\n",
    "games['rz_diff'] = games['home_off_rz_epa_long'] - games['away_off_rz_epa_long']\n",
    "games['penalty_diff'] = games['home_pen_yards_long'] - games['away_pen_yards_long']\n",
    "\n",
    "# Trench Warfare\n",
    "games['sack_mismatch_home'] = games['home_off_sack_rate_long'] - games['away_def_sack_rate_long']\n",
    "games['sack_mismatch_away'] = games['away_off_sack_rate_long'] - games['home_def_sack_rate_long']\n",
    "\n",
    "# --- 2. WALK-FORWARD VALIDATION ---\n",
    "# Removed: div_game, momentum_diff, luck_diff (Noise reduction)\n",
    "X_cols = [\n",
    "    'qb_diff', 'edsr_diff', 'ypp_diff', 'pythag_diff', 'rest_diff',\n",
    "    'sack_mismatch_home', 'sack_mismatch_away',\n",
    "    'st_diff', 'turnover_diff', 'rz_diff', 'penalty_diff',\n",
    "    'home_field_strength', 'roof',\n",
    "    'home_qb_volatility', 'away_qb_volatility'\n",
    "]\n",
    "target = 'result'\n",
    "\n",
    "# Monotonic Constraints\n",
    "mono_constraints = (\n",
    "    1,  # qb_diff\n",
    "    1,  # edsr_diff\n",
    "    1,  # ypp_diff\n",
    "    1,  # pythag_diff\n",
    "    1,  # rest_diff\n",
    "    -1, # sack_mismatch_home\n",
    "    1,  # sack_mismatch_away\n",
    "    1,  # st_diff\n",
    "    -1, # turnover_diff\n",
    "    1,  # rz_diff\n",
    "    -1, # penalty_diff\n",
    "    1,  # home_field\n",
    "    0,  # roof\n",
    "    -1, # home_qb_volatility\n",
    "    1   # away_qb_volatility\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Starting Walk-Forward Validation on {len(X_cols)} Refined Features...\")\n",
    "\n",
    "validation_results = []\n",
    "models = {}\n",
    "test_seasons = [2023, 2024] \n",
    "\n",
    "for test_year in test_seasons:\n",
    "    train_data = games[(games['season'] < test_year) & (games['season'] >= 2018)].dropna(subset=X_cols + [target])\n",
    "    test_data = games[games['season'] == test_year].dropna(subset=X_cols + [target])\n",
    "    \n",
    "    X_train, y_train = train_data[X_cols], train_data[target]\n",
    "    X_test, y_test = test_data[X_cols], test_data[target]\n",
    "    \n",
    "    # Target Clip: ¬±21\n",
    "    y_train = y_train.clip(-21, 21)\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=2000, \n",
    "        learning_rate=0.01, \n",
    "        max_depth=3,              \n",
    "        min_child_weight=20,      \n",
    "        reg_alpha=0.5,            \n",
    "        subsample=0.5,            \n",
    "        colsample_bytree=0.5,     \n",
    "        monotone_constraints=mono_constraints,\n",
    "        early_stopping_rounds=50, \n",
    "        n_jobs=-1, \n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "    \n",
    "    split = int(len(X_train) * 0.9)\n",
    "    X_tr, y_tr = X_train.iloc[:split], y_train.iloc[:split]\n",
    "    X_val, y_val = X_train.iloc[split:], y_train.iloc[split:]\n",
    "    \n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    val_preds = model.predict(X_val)\n",
    "    bias = np.mean(val_preds - y_val)\n",
    "    preds = model.predict(X_test) - bias \n",
    "    \n",
    "    test_data['pred'] = preds\n",
    "    test_data['error'] = test_data['pred'] - test_data['result']\n",
    "    test_data['abs_error'] = test_data['error'].abs()\n",
    "    validation_results.append(test_data)\n",
    "    models[test_year] = model\n",
    "\n",
    "full_audit = pd.concat(validation_results)\n",
    "rmse = np.sqrt(mean_squared_error(full_audit['result'], full_audit['pred']))\n",
    "mae = full_audit['abs_error'].mean()\n",
    "\n",
    "# --- 3. DIAGNOSTICS ---\n",
    "def ascii_bar(val, max_val, width=15): return \"‚ñà\" * int((val / max_val) * width) if max_val > 0 else \"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\nüïµÔ∏è  WALK-FORWARD TEST RESULTS (2023-2024)\\n\" + \"=\"*60)\n",
    "print(f\"1. PERFORMANCE METRICS\")\n",
    "print(f\"   RMSE: {rmse:.4f}\")\n",
    "print(f\"   MAE:  {mae:.4f}\")\n",
    "\n",
    "print(f\"\\n2. BETTING SIMULATION (Refined Golden Model)\")\n",
    "full_audit['spread_line'] = full_audit['spread_line'].fillna(0)\n",
    "full_audit['home_cover'] = np.where(full_audit['result'] > full_audit['spread_line'], 1, 0)\n",
    "full_audit['away_cover'] = np.where(full_audit['result'] < full_audit['spread_line'], 1, 0)\n",
    "full_audit['push'] = np.where(full_audit['result'] == full_audit['spread_line'], 1, 0)\n",
    "\n",
    "for threshold in [1.5, 2.5, 3.5]:\n",
    "    bets = full_audit.copy()\n",
    "    bets['bet_home'] = np.where(bets['pred'] > (bets['spread_line'] + threshold), 1, 0)\n",
    "    bets['bet_away'] = np.where(bets['pred'] < (bets['spread_line'] - threshold), 1, 0)\n",
    "    \n",
    "    wins = len(bets[(bets['bet_home'] == 1) & (bets['home_cover'] == 1)]) + len(bets[(bets['bet_away'] == 1) & (bets['away_cover'] == 1)])\n",
    "    losses = len(bets[(bets['bet_home'] == 1) & (bets['away_cover'] == 1)]) + len(bets[(bets['bet_away'] == 1) & (bets['home_cover'] == 1)])\n",
    "    pushes = len(bets[(bets['bet_home'] == 1) & (bets['push'] == 1)]) + len(bets[(bets['bet_away'] == 1) & (bets['push'] == 1)])\n",
    "    \n",
    "    win_pct = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"   Edge > {threshold}: {wins}-{losses}-{pushes} ({win_pct:.2%})\")\n",
    "\n",
    "print(f\"\\n3. FEATURE IMPORTANCE\")\n",
    "latest_model = models[2024]\n",
    "imps = pd.DataFrame({'f': X_cols, 'i': latest_model.feature_importances_}).sort_values('i', ascending=False)\n",
    "for _, r in imps.iterrows(): print(f\"{r['f']:<25} | {r['i']:.4f} | {ascii_bar(r['i'], imps['i'].max())}\")\n",
    "\n",
    "# Final Train\n",
    "print(\"\\nüöÄ Retraining Master Model on ALL Data (2018-2024)...\")\n",
    "y_final = games[target].clip(-21, 21)\n",
    "final_model = xgb.XGBRegressor(n_estimators=2000, learning_rate=0.01, max_depth=3, min_child_weight=20, reg_alpha=0.5, subsample=0.5, colsample_bytree=0.5, monotone_constraints=mono_constraints, n_jobs=-1, objective='reg:squarederror')\n",
    "final_model.fit(games[X_cols], y_final, verbose=False)\n",
    "print(\"‚úÖ Master Model Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ff4cba2-4463-46c8-aa5d-1fcb75ebb75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèà WEEK 15 HANDICAPPER SHEET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_86c0c_row0_col5, #T_86c0c_row1_col5, #T_86c0c_row2_col5, #T_86c0c_row3_col5, #T_86c0c_row4_col5, #T_86c0c_row5_col5, #T_86c0c_row6_col5, #T_86c0c_row7_col5, #T_86c0c_row8_col5, #T_86c0c_row9_col5, #T_86c0c_row10_col5, #T_86c0c_row11_col5 {\n",
       "  color: #D00000;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_86c0c_row0_col6, #T_86c0c_row1_col6, #T_86c0c_row2_col6, #T_86c0c_row3_col6, #T_86c0c_row4_col6, #T_86c0c_row5_col6, #T_86c0c_row6_col6, #T_86c0c_row7_col6 {\n",
       "  background-color: #ffcccc;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_86c0c_row12_col5, #T_86c0c_row13_col5, #T_86c0c_row14_col5 {\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_86c0c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_86c0c_level0_col0\" class=\"col_heading level0 col0\" >Matchup</th>\n",
       "      <th id=\"T_86c0c_level0_col1\" class=\"col_heading level0 col1\" >QBs</th>\n",
       "      <th id=\"T_86c0c_level0_col2\" class=\"col_heading level0 col2\" >Vegas</th>\n",
       "      <th id=\"T_86c0c_level0_col3\" class=\"col_heading level0 col3\" >Fair_Line</th>\n",
       "      <th id=\"T_86c0c_level0_col4\" class=\"col_heading level0 col4\" >Edge</th>\n",
       "      <th id=\"T_86c0c_level0_col5\" class=\"col_heading level0 col5\" >Action</th>\n",
       "      <th id=\"T_86c0c_level0_col6\" class=\"col_heading level0 col6\" >Conf</th>\n",
       "      <th id=\"T_86c0c_level0_col7\" class=\"col_heading level0 col7\" >Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row0_col0\" class=\"data row0 col0\" >NYJ @ JAX</td>\n",
       "      <td id=\"T_86c0c_row0_col1\" class=\"data row0 col1\" >T.Taylor vs T.Lawrence</td>\n",
       "      <td id=\"T_86c0c_row0_col2\" class=\"data row0 col2\" >JAX -14.0</td>\n",
       "      <td id=\"T_86c0c_row0_col3\" class=\"data row0 col3\" >JAX -4.3</td>\n",
       "      <td id=\"T_86c0c_row0_col4\" class=\"data row0 col4\" >-9.700000</td>\n",
       "      <td id=\"T_86c0c_row0_col5\" class=\"data row0 col5\" >BET NYJ</td>\n",
       "      <td id=\"T_86c0c_row0_col6\" class=\"data row0 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row1_col0\" class=\"data row1 col0\" >CLE @ CHI</td>\n",
       "      <td id=\"T_86c0c_row1_col1\" class=\"data row1 col1\" >S.Sanders vs C.Williams</td>\n",
       "      <td id=\"T_86c0c_row1_col2\" class=\"data row1 col2\" >CHI -7.5</td>\n",
       "      <td id=\"T_86c0c_row1_col3\" class=\"data row1 col3\" >CHI -16.7</td>\n",
       "      <td id=\"T_86c0c_row1_col4\" class=\"data row1 col4\" >9.200000</td>\n",
       "      <td id=\"T_86c0c_row1_col5\" class=\"data row1 col5\" >BET CHI</td>\n",
       "      <td id=\"T_86c0c_row1_col6\" class=\"data row1 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row2_col0\" class=\"data row2 col0\" >ARI @ HOU</td>\n",
       "      <td id=\"T_86c0c_row2_col1\" class=\"data row2 col1\" >J.Brissett vs C.Stroud</td>\n",
       "      <td id=\"T_86c0c_row2_col2\" class=\"data row2 col2\" >HOU -10.5</td>\n",
       "      <td id=\"T_86c0c_row2_col3\" class=\"data row2 col3\" >HOU -1.6</td>\n",
       "      <td id=\"T_86c0c_row2_col4\" class=\"data row2 col4\" >-8.900000</td>\n",
       "      <td id=\"T_86c0c_row2_col5\" class=\"data row2 col5\" >BET ARI</td>\n",
       "      <td id=\"T_86c0c_row2_col6\" class=\"data row2 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row3_col0\" class=\"data row3 col0\" >TEN @ SF</td>\n",
       "      <td id=\"T_86c0c_row3_col1\" class=\"data row3 col1\" >C.Ward vs B.Purdy</td>\n",
       "      <td id=\"T_86c0c_row3_col2\" class=\"data row3 col2\" >SF -12.5</td>\n",
       "      <td id=\"T_86c0c_row3_col3\" class=\"data row3 col3\" >SF -21.0</td>\n",
       "      <td id=\"T_86c0c_row3_col4\" class=\"data row3 col4\" >8.500000</td>\n",
       "      <td id=\"T_86c0c_row3_col5\" class=\"data row3 col5\" >BET SF</td>\n",
       "      <td id=\"T_86c0c_row3_col6\" class=\"data row3 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row4_col0\" class=\"data row4 col0\" >MIN @ DAL</td>\n",
       "      <td id=\"T_86c0c_row4_col1\" class=\"data row4 col1\" >J.McCarthy vs D.Prescott</td>\n",
       "      <td id=\"T_86c0c_row4_col2\" class=\"data row4 col2\" >DAL -5.5</td>\n",
       "      <td id=\"T_86c0c_row4_col3\" class=\"data row4 col3\" >DAL -13.2</td>\n",
       "      <td id=\"T_86c0c_row4_col4\" class=\"data row4 col4\" >7.800000</td>\n",
       "      <td id=\"T_86c0c_row4_col5\" class=\"data row4 col5\" >BET DAL</td>\n",
       "      <td id=\"T_86c0c_row4_col6\" class=\"data row4 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row5_col0\" class=\"data row5 col0\" >BUF @ NE</td>\n",
       "      <td id=\"T_86c0c_row5_col1\" class=\"data row5 col1\" >J.Allen vs D.Maye</td>\n",
       "      <td id=\"T_86c0c_row5_col2\" class=\"data row5 col2\" >NE +1.5</td>\n",
       "      <td id=\"T_86c0c_row5_col3\" class=\"data row5 col3\" >NE -5.8</td>\n",
       "      <td id=\"T_86c0c_row5_col4\" class=\"data row5 col4\" >7.300000</td>\n",
       "      <td id=\"T_86c0c_row5_col5\" class=\"data row5 col5\" >BET NE</td>\n",
       "      <td id=\"T_86c0c_row5_col6\" class=\"data row5 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row6_col0\" class=\"data row6 col0\" >IND @ SEA</td>\n",
       "      <td id=\"T_86c0c_row6_col1\" class=\"data row6 col1\" >D.Jones vs S.Darnold</td>\n",
       "      <td id=\"T_86c0c_row6_col2\" class=\"data row6 col2\" >SEA -14.0</td>\n",
       "      <td id=\"T_86c0c_row6_col3\" class=\"data row6 col3\" >SEA -8.5</td>\n",
       "      <td id=\"T_86c0c_row6_col4\" class=\"data row6 col4\" >-5.500000</td>\n",
       "      <td id=\"T_86c0c_row6_col5\" class=\"data row6 col5\" >BET IND</td>\n",
       "      <td id=\"T_86c0c_row6_col6\" class=\"data row6 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row7_col0\" class=\"data row7 col0\" >BAL @ CIN</td>\n",
       "      <td id=\"T_86c0c_row7_col1\" class=\"data row7 col1\" >L.Jackson vs J.Burrow</td>\n",
       "      <td id=\"T_86c0c_row7_col2\" class=\"data row7 col2\" >CIN +2.5</td>\n",
       "      <td id=\"T_86c0c_row7_col3\" class=\"data row7 col3\" >CIN -2.5</td>\n",
       "      <td id=\"T_86c0c_row7_col4\" class=\"data row7 col4\" >5.000000</td>\n",
       "      <td id=\"T_86c0c_row7_col5\" class=\"data row7 col5\" >BET CIN</td>\n",
       "      <td id=\"T_86c0c_row7_col6\" class=\"data row7 col6\" >üî• STRONG</td>\n",
       "      <td id=\"T_86c0c_row7_col7\" class=\"data row7 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row8_col0\" class=\"data row8 col0\" >LV @ PHI</td>\n",
       "      <td id=\"T_86c0c_row8_col1\" class=\"data row8 col1\" >G.Smith vs J.Hurts</td>\n",
       "      <td id=\"T_86c0c_row8_col2\" class=\"data row8 col2\" >PHI -12.5</td>\n",
       "      <td id=\"T_86c0c_row8_col3\" class=\"data row8 col3\" >PHI -9.1</td>\n",
       "      <td id=\"T_86c0c_row8_col4\" class=\"data row8 col4\" >-3.400000</td>\n",
       "      <td id=\"T_86c0c_row8_col5\" class=\"data row8 col5\" >BET LV</td>\n",
       "      <td id=\"T_86c0c_row8_col6\" class=\"data row8 col6\" >‚ö†Ô∏è LEAN</td>\n",
       "      <td id=\"T_86c0c_row8_col7\" class=\"data row8 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row9_col0\" class=\"data row9 col0\" >MIA @ PIT</td>\n",
       "      <td id=\"T_86c0c_row9_col1\" class=\"data row9 col1\" >T.Tagovailoa vs A.Rodgers</td>\n",
       "      <td id=\"T_86c0c_row9_col2\" class=\"data row9 col2\" >PIT -3.0</td>\n",
       "      <td id=\"T_86c0c_row9_col3\" class=\"data row9 col3\" >PIT -0.2</td>\n",
       "      <td id=\"T_86c0c_row9_col4\" class=\"data row9 col4\" >-2.800000</td>\n",
       "      <td id=\"T_86c0c_row9_col5\" class=\"data row9 col5\" >BET MIA</td>\n",
       "      <td id=\"T_86c0c_row9_col6\" class=\"data row9 col6\" >‚ö†Ô∏è LEAN</td>\n",
       "      <td id=\"T_86c0c_row9_col7\" class=\"data row9 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row10_col0\" class=\"data row10 col0\" >CAR @ NO</td>\n",
       "      <td id=\"T_86c0c_row10_col1\" class=\"data row10 col1\" >B.Young vs T.Shough</td>\n",
       "      <td id=\"T_86c0c_row10_col2\" class=\"data row10 col2\" >NO +2.5</td>\n",
       "      <td id=\"T_86c0c_row10_col3\" class=\"data row10 col3\" >NO +5.1</td>\n",
       "      <td id=\"T_86c0c_row10_col4\" class=\"data row10 col4\" >-2.600000</td>\n",
       "      <td id=\"T_86c0c_row10_col5\" class=\"data row10 col5\" >BET CAR</td>\n",
       "      <td id=\"T_86c0c_row10_col6\" class=\"data row10 col6\" >‚ö†Ô∏è LEAN</td>\n",
       "      <td id=\"T_86c0c_row10_col7\" class=\"data row10 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row11_col0\" class=\"data row11 col0\" >WAS @ NYG</td>\n",
       "      <td id=\"T_86c0c_row11_col1\" class=\"data row11 col1\" >M.Mariota vs J.Winston</td>\n",
       "      <td id=\"T_86c0c_row11_col2\" class=\"data row11 col2\" >NYG -2.5</td>\n",
       "      <td id=\"T_86c0c_row11_col3\" class=\"data row11 col3\" >NYG -0.2</td>\n",
       "      <td id=\"T_86c0c_row11_col4\" class=\"data row11 col4\" >-2.300000</td>\n",
       "      <td id=\"T_86c0c_row11_col5\" class=\"data row11 col5\" >BET WAS</td>\n",
       "      <td id=\"T_86c0c_row11_col6\" class=\"data row11 col6\" >‚ö†Ô∏è LEAN</td>\n",
       "      <td id=\"T_86c0c_row11_col7\" class=\"data row11 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row12_col0\" class=\"data row12 col0\" >LAC @ KC</td>\n",
       "      <td id=\"T_86c0c_row12_col1\" class=\"data row12 col1\" >J.Herbert vs P.Mahomes</td>\n",
       "      <td id=\"T_86c0c_row12_col2\" class=\"data row12 col2\" >KC -6.0</td>\n",
       "      <td id=\"T_86c0c_row12_col3\" class=\"data row12 col3\" >KC -7.7</td>\n",
       "      <td id=\"T_86c0c_row12_col4\" class=\"data row12 col4\" >1.700000</td>\n",
       "      <td id=\"T_86c0c_row12_col5\" class=\"data row12 col5\" >PASS</td>\n",
       "      <td id=\"T_86c0c_row12_col6\" class=\"data row12 col6\" ></td>\n",
       "      <td id=\"T_86c0c_row12_col7\" class=\"data row12 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row13_col0\" class=\"data row13 col0\" >DET @ LA</td>\n",
       "      <td id=\"T_86c0c_row13_col1\" class=\"data row13 col1\" >J.Goff vs M.Stafford</td>\n",
       "      <td id=\"T_86c0c_row13_col2\" class=\"data row13 col2\" >LA -6.0</td>\n",
       "      <td id=\"T_86c0c_row13_col3\" class=\"data row13 col3\" >LA -5.0</td>\n",
       "      <td id=\"T_86c0c_row13_col4\" class=\"data row13 col4\" >-1.000000</td>\n",
       "      <td id=\"T_86c0c_row13_col5\" class=\"data row13 col5\" >PASS</td>\n",
       "      <td id=\"T_86c0c_row13_col6\" class=\"data row13 col6\" ></td>\n",
       "      <td id=\"T_86c0c_row13_col7\" class=\"data row13 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86c0c_row14_col0\" class=\"data row14 col0\" >GB @ DEN</td>\n",
       "      <td id=\"T_86c0c_row14_col1\" class=\"data row14 col1\" >J.Love vs B.Nix</td>\n",
       "      <td id=\"T_86c0c_row14_col2\" class=\"data row14 col2\" >DEN +1.5</td>\n",
       "      <td id=\"T_86c0c_row14_col3\" class=\"data row14 col3\" >DEN +1.3</td>\n",
       "      <td id=\"T_86c0c_row14_col4\" class=\"data row14 col4\" >0.200000</td>\n",
       "      <td id=\"T_86c0c_row14_col5\" class=\"data row14 col5\" >PASS</td>\n",
       "      <td id=\"T_86c0c_row14_col6\" class=\"data row14 col6\" ></td>\n",
       "      <td id=\"T_86c0c_row14_col7\" class=\"data row14 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18aa8663bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "FIX_VEGAS_SIGNS = True \n",
    "QB_OVERRIDES = {} \n",
    "\n",
    "def run_dashboard(model, schedule_df, pbp_stats_df, qb_db, feature_cols):\n",
    "    current_season = 2025\n",
    "    upcoming = schedule_df[(schedule_df['season'] == current_season) & (schedule_df['result'].isna())]\n",
    "    if upcoming.empty: return print(\"‚ö†Ô∏è No upcoming games found.\")\n",
    "\n",
    "    next_week = upcoming['week'].min()\n",
    "    week_df = upcoming[upcoming['week'] == next_week].copy()\n",
    "    latest_stats = pbp_stats_df.sort_values(['season', 'week']).groupby('team').tail(1).set_index('team')\n",
    "    \n",
    "    recent_pbp = pbp[(pbp['season'] == current_season) & (pbp['week'] >= next_week - 3)]\n",
    "    default_starters = recent_pbp[recent_pbp['pass']==1].groupby(['posteam', 'name'])['play_id'].count().reset_index().sort_values('play_id', ascending=False).groupby('posteam').head(1)\n",
    "    default_starters = default_starters.set_index('posteam')['name'].to_dict()\n",
    "    \n",
    "    full_schedule = schedule_df.copy()\n",
    "    full_schedule['gameday'] = pd.to_datetime(full_schedule['gameday'])\n",
    "    def get_rest(team, target_week):\n",
    "        tg = full_schedule[((full_schedule['home_team'] == team) | (full_schedule['away_team'] == team)) & (full_schedule['season'] == current_season)].sort_values('gameday')\n",
    "        pg = tg[tg['week'] < target_week]\n",
    "        if pg.empty: return 7\n",
    "        return min((tg[tg['week'] == target_week].iloc[0]['gameday'] - pg.iloc[-1]['gameday']).days, 14)\n",
    "\n",
    "    def get_qb_epa(team, qb_name):\n",
    "        try:\n",
    "            row = qb_db[(qb_db['season'] == current_season) & (qb_db['posteam'] == team) & (qb_db['name'] == qb_name)]\n",
    "            if not row.empty: return row.iloc[0]['epa']\n",
    "            row = qb_db[(qb_db['season'] == current_season - 1) & (qb_db['name'] == qb_name)]\n",
    "            if not row.empty: return row.iloc[0]['epa']\n",
    "            return None \n",
    "        except: return None\n",
    "\n",
    "    betting_data = []\n",
    "    for _, game in week_df.iterrows():\n",
    "        home, away = game['home_team'], game['away_team']\n",
    "        raw_spread = game['spread_line']\n",
    "        vegas_line = 0.0 if pd.isna(raw_spread) else (-1 * raw_spread if FIX_VEGAS_SIGNS else raw_spread)\n",
    "        vegas_display = \"N/A\" if pd.isna(raw_spread) else f\"{home} {vegas_line:.1f}\" if vegas_line < 0 else f\"{home} +{vegas_line:.1f}\"\n",
    "\n",
    "        if home not in latest_stats.index or away not in latest_stats.index: continue\n",
    "        h, a = latest_stats.loc[home], latest_stats.loc[away]\n",
    "\n",
    "        h_qb_name = QB_OVERRIDES.get(home, default_starters.get(home, \"Unknown\"))\n",
    "        a_qb_name = QB_OVERRIDES.get(away, default_starters.get(away, \"Unknown\"))\n",
    "        h_qb_epa = get_qb_epa(home, h_qb_name)\n",
    "        a_qb_epa = get_qb_epa(away, a_qb_name)\n",
    "        \n",
    "        h_pass_epa = h_qb_epa if h_qb_epa is not None else h.get('off_pass_epa_long', 0)\n",
    "        a_pass_epa = a_qb_epa if a_qb_epa is not None else a.get('off_pass_epa_long', 0)\n",
    "        \n",
    "        data = {}\n",
    "        data['qb_diff'] = h_pass_epa - a_pass_epa\n",
    "        data['edsr_diff'] = h.get('off_edsr_long', 0) - a.get('off_edsr_long', 0)\n",
    "        data['ypp_diff'] = h.get('off_ypp_long', 0) - a.get('off_ypp_long', 0)\n",
    "        data['pythag_diff'] = h.get('pythag_wins', 0.5) - a.get('pythag_wins', 0.5)\n",
    "        data['rest_diff'] = get_rest(home, next_week) - get_rest(away, next_week)\n",
    "        data['st_diff'] = h.get('st_epa_long', 0) - a.get('st_epa_long', 0)\n",
    "        data['turnover_diff'] = h.get('turnovers_lost_long', 0) - a.get('turnovers_lost_long', 0)\n",
    "        data['rz_diff'] = h.get('off_rz_epa_long', 0) - a.get('off_rz_epa_long', 0)\n",
    "        data['penalty_diff'] = h.get('pen_yards_long', 0) - a.get('pen_yards_long', 0)\n",
    "        data['sack_mismatch_home'] = h.get('off_sack_rate_long', 0) - a.get('def_sack_rate_long', 0)\n",
    "        data['sack_mismatch_away'] = a.get('off_sack_rate_long', 0) - h.get('def_sack_rate_long', 0)\n",
    "        data['div_game'] = 1 if game['div_game'] == 1 else 0\n",
    "        data['home_field_strength'] = 2.0 \n",
    "        r_val = {'outdoors': 0, 'open': 0, 'closed': 1, 'dome': 1}.get(game['roof'], 0)\n",
    "        data['roof'] = r_val\n",
    "        data['home_qb_volatility'] = h.get('qb_volatility', 0)\n",
    "        data['away_qb_volatility'] = a.get('qb_volatility', 0)\n",
    "        \n",
    "        input_df = pd.DataFrame([data]).reindex(columns=feature_cols, fill_value=0)\n",
    "        raw_pred = -1 * final_model.predict(input_df)[0]\n",
    "        \n",
    "        fair_line = raw_pred\n",
    "        if fair_line > 21: fair_line = 21\n",
    "        if fair_line < -21: fair_line = -21\n",
    "        \n",
    "        if vegas_display != \"N/A\":\n",
    "            diff = fair_line - vegas_line\n",
    "            if abs(diff) > 10: fair_line = vegas_line + (diff * 0.5) \n",
    "        \n",
    "        edge = vegas_line - fair_line if vegas_display != \"N/A\" else 0.0\n",
    "        action = \"PASS\"\n",
    "        confidence = \"\"\n",
    "        \n",
    "        if vegas_display != \"N/A\":\n",
    "            if abs(edge) >= 3.5:\n",
    "                confidence = \"üî• STRONG\"\n",
    "                action = f\"BET {home}\" if edge > 0 else f\"BET {away}\"\n",
    "            elif abs(edge) >= 2.0:\n",
    "                confidence = \"‚ö†Ô∏è LEAN\"\n",
    "                action = f\"BET {home}\" if edge > 0 else f\"BET {away}\"\n",
    "        \n",
    "        f_str = f\"{home} {fair_line:.1f}\" if fair_line < 0 else f\"{home} +{fair_line:.1f}\"\n",
    "        final_note = \"\"\n",
    "        if h_qb_name == \"Unknown\" or a_qb_name == \"Unknown\": final_note += \"‚ö†Ô∏è Unknown QB \"\n",
    "        if h_qb_epa is None: final_note += f\"‚ö†Ô∏è Using Team Stats for {home} \"\n",
    "        \n",
    "        betting_data.append({'Matchup': f\"{away} @ {home}\", 'QBs': f\"{a_qb_name} vs {h_qb_name}\", 'Vegas': vegas_display, 'Fair_Line': f_str, 'Edge': round(edge, 1) if vegas_display != \"N/A\" else \"N/A\", 'Action': action, 'Conf': confidence, 'Note': final_note})\n",
    "        \n",
    "    df = pd.DataFrame(betting_data)\n",
    "    print(f\"\\nüèà WEEK {next_week} HANDICAPPER SHEET\")\n",
    "    def style_action(val): return 'color: #D00000; font-weight: bold;' if \"BET\" in val else 'color: black;'\n",
    "    def style_conf(val): return 'background-color: #ffcccc; font-weight: bold;' if \"STRONG\" in val else ''\n",
    "    \n",
    "    df['Sort'] = df['Edge'].apply(lambda x: abs(x) if isinstance(x, (int, float)) else 0)\n",
    "    styled = df.sort_values('Sort', ascending=False).drop(columns=['Sort']).style.applymap(style_action, subset=['Action']).applymap(style_conf, subset=['Conf']).hide(axis='index')\n",
    "    display(styled)\n",
    "\n",
    "run_dashboard(final_model, schedule, stats, qb_db, X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3dda10fc-5056-4c82-9508-e65c775719b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ update_db.py FIXED! Run 'python update_db.py' now.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "CACHE_PATH = \"data/nfl_db.pkl\"\n",
    "\n",
    "print(\"üîç DIAGNOSTIC CHECK...\")\n",
    "\n",
    "if not os.path.exists(CACHE_PATH):\n",
    "    print(\"‚ùå No DB found. Please run update_db.py first.\")\n",
    "else:\n",
    "    with open(CACHE_PATH, 'rb') as f:\n",
    "        db = pickle.load(f)\n",
    "    \n",
    "    games = db['games_df']\n",
    "    current_season = db['current_season']\n",
    "    print(f\"‚úÖ Loaded DB. Season: {current_season}\")\n",
    "    \n",
    "    # 1. Check Game Count\n",
    "    season_games = games[games['season'] == current_season]\n",
    "    print(f\"üìä Total Games in {current_season}: {len(season_games)}\")\n",
    "    \n",
    "    # 2. Check Results & Spreads\n",
    "    graded = season_games[season_games['result'].notna()]\n",
    "    with_odds = season_games[season_games['spread_line'].notna()]\n",
    "    print(f\"   - Completed Games: {len(graded)}\")\n",
    "    print(f\"   - Games with Odds: {len(with_odds)}\")\n",
    "    \n",
    "    # 3. Check Features (The likely culprit)\n",
    "    # Check if 'qb_diff' is all zeros\n",
    "    non_zero_feats = season_games[season_games['qb_diff'] != 0]\n",
    "    print(f\"   - Games with valid QB Stats: {len(non_zero_feats)}\")\n",
    "    \n",
    "    if len(non_zero_feats) == 0:\n",
    "        print(\"\\n‚ö†Ô∏è CRITICAL ISSUE FOUND: All Feature Stats are ZERO.\")\n",
    "        print(\"   This means the Merge between Schedule and Stats failed.\")\n",
    "        print(\"   Likely cause: Team Name Mismatch (e.g. 'WAS' vs 'WSH').\")\n",
    "    \n",
    "    # 4. PREVIEW DATA\n",
    "    print(\"\\nüßê Sample Data Row (First 5 columns):\")\n",
    "    print(season_games[['week', 'home_team', 'away_team', 'spread_line', 'qb_diff']].tail(3))\n",
    "    \n",
    "    # --- AUTOMATIC REPAIR ATTEMPT ---\n",
    "    if len(non_zero_feats) == 0:\n",
    "        print(\"\\nüõ†Ô∏è  ATTEMPTING REPAIR...\")\n",
    "        # Reload raw data\n",
    "        import nfl_data_py as nfl\n",
    "        \n",
    "        # Mapping Dictionary for common mismatches\n",
    "        team_map = {'WSH': 'WAS', 'HST': 'HOU', 'BLT': 'BAL', 'CLV': 'CLE', 'ARZ': 'ARI'}\n",
    "        \n",
    "        # 1. Re-run stats engine manually here to test\n",
    "        print(\"   -> Fetching fresh PBP...\")\n",
    "        pbp = nfl.import_pbp_data([current_season])\n",
    "        \n",
    "        # FIX TEAM NAMES IN PBP\n",
    "        pbp['posteam'] = pbp['posteam'].replace(team_map)\n",
    "        pbp['defteam'] = pbp['defteam'].replace(team_map)\n",
    "        \n",
    "        print(\"   -> Recalculating Stats...\")\n",
    "        # (Simplified Stats Logic for Repair)\n",
    "        stats = pbp.groupby(['season', 'week', 'posteam']).agg({'epa': 'mean'}).reset_index().rename(columns={'posteam': 'team', 'epa': 'off_epa'})\n",
    "        stats['off_epa_long'] = stats.groupby('team')['off_epa'].transform(lambda x: x.shift(1).ewm(span=10).mean())\n",
    "        \n",
    "        # Merge back to games\n",
    "        games_repair = games.copy()\n",
    "        # Drop old broken columns if they exist\n",
    "        if 'home_off_epa_long' in games_repair.columns:\n",
    "            games_repair = games_repair.drop(columns=['home_off_epa_long', 'away_off_epa_long'])\n",
    "            \n",
    "        games_repair = games_repair.merge(stats[['season', 'week', 'team', 'off_epa_long']], left_on=['season', 'week', 'home_team'], right_on=['season', 'week', 'team'], how='left').rename(columns={'off_epa_long': 'home_off_epa_long'}).drop(columns=['team'])\n",
    "        games_repair = games_repair.merge(stats[['season', 'week', 'team', 'off_epa_long']], left_on=['season', 'week', 'away_team'], right_on=['season', 'week', 'team'], how='left').rename(columns={'off_epa_long': 'away_off_epa_long'}).drop(columns=['team'])\n",
    "        \n",
    "        # Check if we fixed it\n",
    "        fixed_count = len(games_repair[games_repair['home_off_epa_long'].notna()])\n",
    "        print(f\"   -> Repair Result: {fixed_count} games now have EPA stats.\")\n",
    "        \n",
    "        if fixed_count > 0:\n",
    "            print(\"‚úÖ Repair Successful. Please update 'update_db.py' to handle team name mapping.\")\n",
    "\n",
    "    # 5. FORCE PREDICTION CHECK\n",
    "    print(\"\\nüé≤ RUNNING TEST PREDICTION...\")\n",
    "    model = db['model']\n",
    "    # Pick a game with odds\n",
    "    if not with_odds.empty:\n",
    "        test_game = with_odds.iloc[-1]\n",
    "        X = pd.DataFrame([test_game[db['model'].feature_names_in_]])\n",
    "        pred = -1 * model.predict(X)[0]\n",
    "        print(f\"   Matchup: {test_game['away_team']} @ {test_game['home_team']}\")\n",
    "        print(f\"   Vegas: {test_game['spread_line']}\")\n",
    "        print(f\"   Model: {pred:.2f}\")\n",
    "        print(f\"   Edge:  {(-1 * test_game['spread_line']) - pred:.2f}\")\n",
    "    else:\n",
    "        print(\"   No games with odds found to test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18d1d8-c728-4bd7-be7a-d383dc1a49d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
